{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b25b9ae1",
   "metadata": {},
   "source": [
    "1. Simple Linear Regression is a way to predict the value of the outcome variable based on the predictor variable. We are trying to draw a straight line that best fits the data points we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4335cdc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fabc337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "beta_0 = 5\n",
    "beta_1 = 2   # Slope\n",
    "sigma = 1    # Standard deviation of the error term\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.linspace(0, 10, 50)\n",
    "\n",
    "Y_true = beta_0 + beta_1 * X\n",
    "\n",
    "error = norm.rvs(0, sigma, size=X.shape)\n",
    "Y = Y_true + error\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X, Y_true, label=\"True Line (no error)\", color=\"green\", linestyle=\"--\")\n",
    "plt.scatter(X, Y, color=\"blue\", alpha=0.6, label=\"Observed Y (with error)\")\n",
    "plt.xlabel(\"Predictor (X)\")\n",
    "plt.ylabel(\"Outcome (Y)\")\n",
    "plt.legend()\n",
    "plt.title(\"Simple Linear Regression Model with Random Noise\")\n",
    "plt.show()\n",
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19842818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf \n",
    "import plotly.express as px\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.linspace(0, 10, 50)\n",
    "beta_0 = 5\n",
    "beta_1 = 2\n",
    "sigma = 1 \n",
    "error = np.random.normal(0, sigma, size=X.shape)\n",
    "Y = beta_0 + beta_1 * X + error\n",
    "\n",
    "df = pd.DataFrame({'x': X, 'Y': Y})\n",
    "\n",
    "model_data_specification = smf.ols(\"Y ~ x\", data=df) \n",
    "\n",
    "fitted_model = model_data_specification.fit()\n",
    "\n",
    "fitted_model.summary() \n",
    "fitted_model.summary().tables[1] \n",
    "fitted_model.params \n",
    "fitted_model.params.values \n",
    "fitted_model.rsquared \n",
    "\n",
    "df['Data'] = 'Data' \n",
    "\n",
    "fig = px.scatter(df, x='x', y='Y', color='Data', trendline='ols', title='Y vs. x')\n",
    "\n",
    "fig.add_scatter(x=df['x'], y=fitted_model.fittedvalues, line=dict(color='blue'), name=\"trendline='ols'\")\n",
    "\n",
    "fig.show(renderer=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55749bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import plotly.express as px\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.linspace(0, 10, 50)\n",
    "beta_0 = 5\n",
    "beta_1 = 2\n",
    "sigma = 1\n",
    "error = np.random.normal(0, sigma, size=X.shape)\n",
    "Y = beta_0 + beta_1 * X + error\n",
    "\n",
    "df = pd.DataFrame({'x': X, 'Y': Y})\n",
    "\n",
    "model_data_specification = smf.ols(\"Y ~ x\", data=df)\n",
    "fitted_model = model_data_specification.fit()\n",
    "\n",
    "df['True_Y'] = beta_0 + beta_1 * df['x']\n",
    "\n",
    "df['Data'] = 'Data'\n",
    "fig = px.scatter(df, x='x', y='Y', color='Data', trendline='ols', title='Y vs. x with True Line and Fitted Line')\n",
    "\n",
    "fig.add_scatter(x=df['x'], y=df['True_Y'], mode='lines', line=dict(color='green', dash='dash'), name=\"True Line\")\n",
    "fig.add_scatter(x=df['x'], y=fitted_model.fittedvalues, line=dict(color='blue'), name=\"Fitted Line\")\n",
    "\n",
    "fig.show(renderer=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25958bcf",
   "metadata": {},
   "source": [
    "4. it fitted_model.fittedvalues uses the calculated intercept and slope to find predicted Y values for each point in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8524ff22",
   "metadata": {},
   "source": [
    "5. the ordinary least squares method finds the line that best fits the data by minimizing the total squared differences between observed and predicted values, ensuring that large deviations are penalized and all residuals contribute positively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be19b8",
   "metadata": {},
   "source": [
    "6. R^2 represents the proportion of variation in Y explained by the model. It can be calculated by comparing the total variation in Y to the variation left unexplained by the model. Higher R^2 values indicate a more accurate model. The correlation-squared between Y and the predicted values also gives R^2, which reinforcing how well the model captures the relationship with Y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ba1ee",
   "metadata": {},
   "source": [
    "7. The Simple Linear Regression model assumes a linear relationship, which may not fit well if the data appears curved. It also assumes constant error variance, but if the spread of errors changes across X, this assumption is violated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa88397",
   "metadata": {},
   "source": [
    "8. the null hypothesis states there’s no linear association between geyser duration and waiting time. A low p-value for the slope would suggest rejecting H0, indicating a significant linear relationship; a high p-value would mean insufficient evidence to reject H0, supporting no linear association."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414e8b81",
   "metadata": {},
   "source": [
    "9. For short wait times (<62, <64, <66 minutes), we test if there's still a significant relationship between waiting and duration. A low p-value would indicate a consistent relationship even within short waits, while a high p-value suggests that the association seen in the full data may not apply to shorter waits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3085e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "old_faithful = sns.load_dataset(\"geyser\")\n",
    "\n",
    "long_wait = old_faithful['waiting'] > some_threshold\n",
    "\n",
    "n_bootstrap_samples = 1000\n",
    "bootstrap_slopes = []\n",
    "\n",
    "for _ in range(n_bootstrap_samples):\n",
    "    sample = old_faithful[long_wait].sample(n=160, replace=True)\n",
    "    model = smf.ols('duration ~ waiting', data=sample).fit()\n",
    "    bootstrap_slopes.append(model.params['waiting'])\n",
    "\n",
    "plt.hist(bootstrap_slopes, bins=30, edgecolor='k')\n",
    "plt.title(\"Bootstrapped Sampling Distribution of Slope Coefficients\")\n",
    "plt.xlabel(\"Slope Coefficient\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "beta_0 = 1.65\n",
    "beta_1 = 0\n",
    "sigma = 0.37\n",
    "simulated_slopes = []\n",
    "\n",
    "for _ in range(n_bootstrap_samples):\n",
    "    x = old_faithful[long_wait]['waiting']\n",
    "    y_simulated = beta_0 + beta_1 * x + np.random.normal(0, sigma, size=len(x))\n",
    "    sim_data = pd.DataFrame({'waiting': x, 'duration': y_simulated})\n",
    "    sim_model = smf.ols('duration ~ waiting', data=sim_data).fit()\n",
    "    simulated_slopes.append(sim_model.params['waiting'])\n",
    "\n",
    "plt.hist(simulated_slopes, bins=30, edgecolor='k')\n",
    "plt.title(\"Sampling Distribution of Slope Coefficients (Null Hypothesis)\")\n",
    "plt.xlabel(\"Slope Coefficient\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "ci_lower = np.percentile(bootstrap_slopes, 2.5)\n",
    "ci_upper = np.percentile(bootstrap_slopes, 97.5)\n",
    "print(f\"95% Bootstrapped Confidence Interval for Slope: [{ci_lower}, {ci_upper}]\")\n",
    "\n",
    "contains_zero = ci_lower <= 0 <= ci_upper\n",
    "print(f\"Does the 95% CI contain 0? {'Yes' if contains_zero else 'No'}\")\n",
    "\n",
    "observed_mean_slope = np.mean(bootstrap_slopes)\n",
    "simulated_p_value = np.mean([abs(slope) >= abs(observed_mean_slope) for slope in simulated_slopes])\n",
    "print(f\"Simulated p-value: {simulated_p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7eb81a",
   "metadata": {},
   "source": [
    "11. The indicator model compares average differences between \"long\" and \"short\" waits, while the continuous model shows finer linear trends. A low p-value indicates a significant difference between \"long\" and \"short\" waits; a high p-value suggests no significant difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfdd345",
   "metadata": {},
   "source": [
    "12. Model 1's histogram best supports the normality assumption if it closely follows the bell-shaped curve. Models 2 and 3's histograms likely show deviations from normality due to skewness or heavy tails. Model 4's histogram likely appears bimodal, indicating non-normal residuals due to the indicator variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a46218",
   "metadata": {},
   "source": [
    "13. \n",
    "A. The permutation test shuffles labels between “short” and “long” groups to assess if the observed mean difference could occur by chance under the null hypothesis.\n",
    "B. The bootstrap confidence interval resamples each group to estimate the reliability of the observed mean difference. Unlike the indicator variable model, which uses regression to estimate differences, these methods are non-parametric and make no assumptions about linear relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67615052",
   "metadata": {},
   "source": [
    "14. ALL FINE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
